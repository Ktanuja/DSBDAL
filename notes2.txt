Data Cleaning: This involves identifying and correcting errors or inconsistencies in the data, such as missing values, outliers, and duplicates. Various techniques can be used for data cleaning, such as imputation, removal, and transformation.

Data Integration: This involves combining data from multiple sources to create a unified dataset. Data integration can be challenging as it requires handling data with different formats, structures, and semantics. 
Techniques such as record linkage and data fusion can be used for data integration.

Data Transformation: This involves converting the data into a suitable format for analysis. Common techniques used in data transformation include normalization, standardization, and discretization. Normalization is used to scale the data to a common range, while standardization is used to transform the data to have zero mean and unit variance. Discretization is used to convert continuous data into discrete categories.

Data Reduction: This involves reducing the size of the dataset while preserving the important information. Data reduction can be achieved through techniques such as feature selection and feature extraction. Feature selection involves selecting a subset of relevant features from the dataset, while feature extraction involves transforming the data into a lower-dimensional space while preserving the important information.

Data Discretization: Data discretization refers to a method of converting a huge number of data values into smaller ones so that the evaluation and management of data become easy

There are two forms of data discretization first is supervised discretization, and the second is unsupervised discretization. Supervised discretization refers to a method in which the class data is used. Unsupervised discretization refers to a method depending upon the way which operation proceeds.

Data Normalization: This involves scaling the data to a common range, such as between 0 and 1 or -1 and 1. Normalization is often used to handle data with different units and scales. Common normalization techniques include min-max normalization, z-score normalization, and decimal scaling.


elationship between a dependent (target) and independent (predictor) variables with one or more independent variables.

Regression Analysis helps an individual to understand how the typical value of the dependent variable changes when one of the independent variables is varied, while the other independent variables remain unchanged.

It predicts continuous/real values such as temperature, age, salary, price, etc.
Linear Regression
Logistic Regression
Polynomial Regression
Ridge

Logistics regression 
It is used for predicting the categorical dependent variable using a given set of independent variables.
Data classification is the process of organizing data into categories that make it easy to retrieve, sort and store for future use

Bayes classification algorithm 
it predicts on the basis of the probability of an object

A histogram displays numerical data by grouping data into "bins" of equal width. Each bin is plotted as a bar whose height corresponds to how many data points are in that bin. Bins are also sometimes called "intervals", "classes", or "buckets".

1.	Write a Scala program to check the largest number among three given integers.
	
	// taking three variables
	var a: Int = 70
	var b: Int = 40
	var c: Int = 100

	// condition_1
	if (a > b)
	{
		// condition_2
		if(a > c)
		{
			println("a is largest");
		}
		
		else
		{
			println("c is largest")
		}
	
	}
	
	else
	{
		
		// condition_3
		if(b > c)
		{
			println("b is largest")
		}
		
		else
		{
			println("c is largest")
		}
	}











2) Write a Scala program to reverse an array of integer values.

var nums1 = Array(1789, 2035, 1899, 1456, 2013) 
    println("Orginal array:")
    for ( x <- nums1) {
       print(s"${x}, ")        
     }           
    var result1= test(nums1)
    println("\nReversed array:")
    for ( x <- result1) {
       print(s"${x}, ")        
     }

def test(nums: Array[Int]): Array[Int] = {
    var temp1 = 0
    var temp2 = 0
    var index_position = 0
    var index_last_pos = nums.length - 1   
    while (index_position < index_last_pos) {
    temp1 = nums(index_position)
    temp2 = nums(index_last_pos)
    nums(index_position) = temp2
    nums(index_last_pos) = temp1
    index_position += 1
    index_last_pos -= 1
     }
    nums
}





3) Write a Scala code to merge two integer arrays into a third array


 var IntArray1 = Array(10,11,12,13,14,15)
        var IntArray2 = Array(20,21,22,23,24,25)
        var IntArray3 = new Array[Int](12)
        var count:Int=0
        var count1:Int=0
        
        // Merge IntArray1 and IntArray2 into IntArray3.
        while(count<12)
        {
            if(count<6)
            IntArray3(count)=IntArray1(count)
            else
            {
                IntArray3(count)=IntArray2(count1)
                count1=count1+1
            }
            count=count+1
        }
        
        println("Elements of merged array:")
        count=0
        while(count<12)
        {
            printf("%d ",IntArray3(count))
            count=count+1
        }



Hadoop
.
hadoop fs -mkdir /Tanuja
hadoop fs -mkdir /Tanuja/Input
hadoop fs -put Lab/Input/input.txt /Tanuja/Input
cd Lab
javac -classpath $HADOOP_CLASSPATH -d tut WordCount.java
jar -cvf WordCount.jar .C tut .
hadoop jar WordCount.jar WordCount /Tanuja/Input /Tanuja/Output
hadoop dfs -cat /Tanuja/Output/*

